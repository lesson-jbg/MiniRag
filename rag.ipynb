{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae25d818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b3ba6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\env1\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "CHROMA_DB_DIR = \"chroma_career_db\"\n",
    "COLLECTION_NAME = \"career_knowledge_base\"\n",
    "\n",
    "# Use a local embedding model (no API needed).\n",
    "# You can swap this later to Together / OpenRouter embeddings if you want.\n",
    "embedding_fn = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b98127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# LOAD CAREER DOCS\n",
    "# ==============================\n",
    "\n",
    "def load_career_docs_from_folder(folder_path: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Reads simple text / markdown files from a folder.\n",
    "    Each file represents one career / role description.\n",
    "\n",
    "    Expected structure:\n",
    "        data/careers/\n",
    "            data_analyst.txt\n",
    "            software_engineer.txt\n",
    "            product_manager.txt\n",
    "            ...\n",
    "\n",
    "    Returns:\n",
    "        List of dicts: { \"id\": str, \"text\": str, \"metadata\": dict }\n",
    "    \"\"\"\n",
    "    docs = []\n",
    "\n",
    "    if not os.path.isdir(folder_path):\n",
    "        raise ValueError(f\"Folder not found: {folder_path}\")\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if not filename.lower().endswith((\".txt\", \".md\")):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read().strip()\n",
    "\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        doc_id = os.path.splitext(filename)[0]\n",
    "\n",
    "        docs.append(\n",
    "            {\n",
    "                \"id\": doc_id,\n",
    "                \"text\": text,\n",
    "                \"metadata\": {\n",
    "                    \"filename\": filename,\n",
    "                    \"career_name\": doc_id.replace(\"_\", \" \").title(),\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "    if not docs:\n",
    "        raise ValueError(f\"No .txt/.md files found in folder: {folder_path}\")\n",
    "\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b48e2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# BUILD / LOAD VECTOR DB\n",
    "# ==============================\n",
    "\n",
    "def get_chroma_collection():\n",
    "    \"\"\"\n",
    "    Connect to (or create) a persistent Chroma collection for career knowledge.\n",
    "    \"\"\"\n",
    "    client = chromadb.PersistentClient(path=CHROMA_DB_DIR)\n",
    "\n",
    "    collection = client.get_or_create_collection(\n",
    "        name=COLLECTION_NAME,\n",
    "        embedding_function=embedding_fn,\n",
    "    )\n",
    "\n",
    "    return collection\n",
    "\n",
    "\n",
    "def build_or_update_career_index(career_docs: List[Dict]) -> None:\n",
    "    \"\"\"\n",
    "    Ingest / update the vector DB with career documents.\n",
    "\n",
    "    This should be called once during setup, or whenever you update the corpus.\n",
    "    \"\"\"\n",
    "    collection = get_chroma_collection()\n",
    "\n",
    "    # Clear collection if you want a clean rebuild (optional)\n",
    "    # collection.delete(where={})\n",
    "\n",
    "    ids = [doc[\"id\"] for doc in career_docs]\n",
    "    texts = [doc[\"text\"] for doc in career_docs]\n",
    "    metadatas = [doc[\"metadata\"] for doc in career_docs]\n",
    "\n",
    "    collection.upsert(ids=ids, documents=texts, metadatas=metadatas)\n",
    "\n",
    "    print(f\"[INFO] Indexed {len(ids)} career documents into Chroma.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0d213c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# RETRIEVAL: GIVEN RESUME TEXT\n",
    "# ==============================\n",
    "\n",
    "def retrieve_relevant_careers(\n",
    "    resume_text: str,\n",
    "    top_k: int = 5,\n",
    ") -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Core retrieval function (simple RAG):\n",
    "\n",
    "    Input:\n",
    "        resume_text: Plain text extracted from the resume (PDF parsing is upstream).\n",
    "        top_k: Number of most relevant careers to return.\n",
    "\n",
    "    Output:\n",
    "        List of dicts with:\n",
    "            - career_name\n",
    "            - score (distance)\n",
    "            - snippet / full text\n",
    "            - metadata\n",
    "    \"\"\"\n",
    "    if not resume_text or not resume_text.strip():\n",
    "        raise ValueError(\"resume_text is empty. Make sure you parsed the PDF first.\")\n",
    "\n",
    "    collection = get_chroma_collection()\n",
    "\n",
    "    results = collection.query(\n",
    "        query_texts=[resume_text],\n",
    "        n_results=top_k,\n",
    "    )\n",
    "\n",
    "    # Chroma returns dict with lists; we convert to a nicer list of dicts.\n",
    "    retrieved = []\n",
    "    ids = results.get(\"ids\", [[]])[0]\n",
    "    docs = results.get(\"documents\", [[]])[0]\n",
    "    metadatas = results.get(\"metadatas\", [[]])[0]\n",
    "    distances = results.get(\"distances\", [[]])[0] if \"distances\" in results else [None] * len(ids)\n",
    "\n",
    "    for idx, doc_id in enumerate(ids):\n",
    "        retrieved.append(\n",
    "            {\n",
    "                \"id\": doc_id,\n",
    "                \"career_name\": metadatas[idx].get(\"career_name\", doc_id),\n",
    "                \"score\": distances[idx],\n",
    "                \"text\": docs[idx],\n",
    "                \"metadata\": metadatas[idx],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adc81a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Indexed 3 career documents into Chroma.\n",
      "\n",
      "Top matching career paths for this resume:\n",
      "\n",
      "- Data Analyst (score: 0.8273972272872925)\n",
      "- Software Engineer (score: 1.2232584953308105)\n",
      "- Product Manager (score: 1.503218173980713)\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# EXAMPLE: HOW TO USE (for testing)\n",
    "# ==============================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Build index once (e.g., from a folder of career descriptions)\n",
    "    career_folder = \"data/careers\"\n",
    "    docs = load_career_docs_from_folder(career_folder)\n",
    "    build_or_update_career_index(docs)\n",
    "\n",
    "    # 2) Pretend we already parsed a resume PDF\n",
    "    example_resume_text = \"\"\"\n",
    "    I am a Computer Science student with strong experience in Python, data analysis,\n",
    "    machine learning, and SQL. I have worked on projects with pandas, scikit-learn,\n",
    "    and Streamlit. I enjoy building dashboards and working with real-world datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    # 3) Retrieve top-k relevant careers from vector DB\n",
    "    retrieved_careers = retrieve_relevant_careers(example_resume_text, top_k=3)\n",
    "\n",
    "    print(\"\\nTop matching career paths for this resume:\\n\")\n",
    "    for r in retrieved_careers:\n",
    "        print(f\"- {r['career_name']} (score: {r['score']})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
